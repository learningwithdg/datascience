{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 9\n",
    "---\n",
    "\n",
    "## DataStore\n",
    "\n",
    "- RDMS (SQLite, MySQL, PostgreSQL)\n",
    "- Text Format (CSV, JSON)\n",
    "- NoSQL ( MongoDB, CouchDB)\n",
    "- Fast Binary (HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('id', '1'), (' firstname', ' harry'), (' lastname', ' potter'), (' age', ' 17')]), OrderedDict([('id', '2'), (' firstname', ' Hermaine'), (' lastname', ' Granger'), (' age', ' 17')]), OrderedDict([('id', '3'), (' firstname', ' Ron'), (' lastname', ' Weasly'), (' age', ' 17')]), OrderedDict([('id', '4'), (' firstname', ' Neville'), (' lastname', ' Longbottom'), (' age', ' 17')])]\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    print(list(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Color = namedtuple('Color', ['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Color(123, 189, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " firstname\n",
      " harry\n",
      " Hermaine\n",
      " Ron\n",
      " Neville\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['id', 'firstname', 'lastname', 'age'])\n",
    "#     next(reader)\n",
    "    for line in reader:\n",
    "        print(line['firstname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " harry\n",
      " Hermaine\n",
      " Ron\n",
      " Neville\n"
     ]
    }
   ],
   "source": [
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['id', 'firstname', 'lastname', 'age'])\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        print(line['firstname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = iter([1, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x7f0fe6dd13c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4e88e4aaba5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'a') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['id', 'firstname', 'lastname', 'age'])\n",
    "    writer.writerow({'id': 5, 'firstname': 'Luna', 'lastname': 'Lovegood', 'age': 17})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'a') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['id', 'firstname', 'lastname', 'age'])\n",
    "    writer.writerows([\n",
    "        {'id': 6, 'firstname': 'Tom', 'lastname': 'Weasly', 'age': 19},\n",
    "        {'id': 7, 'firstname': 'Tom', 'lastname': 'Weasly', 'age': 19}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data.sqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f0fe6d84b90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('CREATE TABLE characters(id integer, firstname text, lastname text, age integer)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f0fe6d84b90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('INSERT INTO characters(id, firstname, lastname, age) VALUES(11, \"Harry\", \"Potter\", 17)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"INSERT INTO characters(id) VALUES(\" + line['id'] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"INSERT INTO characters(id, firstname, lastname, age) VALUES(?, ?, ?, ?)\"\"\"\n",
    "with open('names.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['id', 'firstname', 'lastname', 'age'])\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        cur.execute(sql, (line['id'], line['firstname'], line['lastname'], line['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f0fe6d84b90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('UPDATE characters SET firstname=\"Bob\" WHERE firstname=\"Tom\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf = h5py.File('datasets.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = hf.create_group('ktm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"datasets.h5\" (mode r+)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm\" (0 members)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/ktm/substation1\" (0 members)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.create_group('substation1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg2 = g1.create_group('substation2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = sg2.create_dataset('statellite_image', (100,), dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"statellite_image\": shape (100,), type \"<i4\">"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dataset in module h5py._hl.dataset object:\n",
      "\n",
      "class Dataset(h5py._hl.base.HLObject)\n",
      " |  Represents an HDF5 dataset\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      h5py._hl.base.HLObject\n",
      " |      h5py._hl.base.CommonStateObject\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |      Create a Numpy array containing the whole dataset.  DON'T THINK\n",
      " |      THIS MEANS DATASETS ARE INTERCHANGABLE WITH ARRAYS.  For one thing,\n",
      " |      you have to read the whole dataset everytime this method is called.\n",
      " |  \n",
      " |  __getitem__(self, args)\n",
      " |      Read a slice from the HDF5 dataset.\n",
      " |      \n",
      " |      Takes slices and recarray-style field names (more than one is\n",
      " |      allowed!) in any order.  Obeys basic NumPy rules, including\n",
      " |      broadcasting.\n",
      " |      \n",
      " |      Also supports:\n",
      " |      \n",
      " |      * Boolean \"mask\" array indexing\n",
      " |  \n",
      " |  __init__(self, bind)\n",
      " |      Create a new Dataset object by binding to a low-level DatasetID.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      BEWARE: Modifications to the yielded data are *NOT* written to file.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Limited to 2**32 on 32-bit systems; Dataset.len() is preferred.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setitem__(self, args, val)\n",
      " |      Write to the HDF5 dataset from a Numpy array.\n",
      " |      \n",
      " |      NumPy's broadcasting rules are honored, for \"simple\" indexing\n",
      " |      (slices and integers).  For advanced indexing, the shapes must\n",
      " |      match.\n",
      " |  \n",
      " |  astype(self, dtype)\n",
      " |      Get a context manager allowing you to perform reads to a\n",
      " |      different destination type, e.g.:\n",
      " |      \n",
      " |      >>> with dataset.astype('f8'):\n",
      " |      ...     double_precision = dataset[0:100:2]\n",
      " |  \n",
      " |  len(self)\n",
      " |      The size of the first axis.  TypeError if scalar.\n",
      " |      \n",
      " |      Use of this method is preferred to len(dset), as Python's built-in\n",
      " |      len() cannot handle values greater then 2**32 on 32-bit systems.\n",
      " |  \n",
      " |  read_direct(self, dest, source_sel=None, dest_sel=None)\n",
      " |      Read data directly from HDF5 into an existing NumPy array.\n",
      " |      \n",
      " |      The destination array must be C-contiguous and writable.\n",
      " |      Selections must be the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  resize(self, size, axis=None)\n",
      " |      Resize the dataset, or the specified axis.\n",
      " |      \n",
      " |      The dataset must be stored in chunked format; it can be resized up to\n",
      " |      the \"maximum shape\" (keyword maxshape) specified at creation time.\n",
      " |      The rank of the dataset cannot be changed.\n",
      " |      \n",
      " |      \"Size\" should be a shape tuple, or if an axis is specified, an integer.\n",
      " |      \n",
      " |      BEWARE: This functions differently than the NumPy resize() method!\n",
      " |      The data is not \"reshuffled\" to fit in the new shape; each axis is\n",
      " |      grown or shrunk independently.  The coordinates of existing data are\n",
      " |      fixed.\n",
      " |  \n",
      " |  write_direct(self, source, source_sel=None, dest_sel=None)\n",
      " |      Write data directly to HDF5 from a NumPy array.\n",
      " |      \n",
      " |      The source array must be C-contiguous.  Selections must be\n",
      " |      the output of numpy.s_[<args>].\n",
      " |      \n",
      " |      Broadcasting is supported for simple indexing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  chunks\n",
      " |      Dataset chunks (or None)\n",
      " |  \n",
      " |  compression\n",
      " |      Compression strategy (or None)\n",
      " |  \n",
      " |  compression_opts\n",
      " |      Compression setting.  Int(0-9) for gzip, 2-tuple for szip.\n",
      " |  \n",
      " |  dims\n",
      " |      Access dimension scales attached to this dataset.\n",
      " |  \n",
      " |  dtype\n",
      " |      Numpy dtype representing the datatype\n",
      " |  \n",
      " |  fillvalue\n",
      " |      Fill value for this dataset (0 by default)\n",
      " |  \n",
      " |  fletcher32\n",
      " |      Fletcher32 filter is present (T/F)\n",
      " |  \n",
      " |  maxshape\n",
      " |      Shape up to which this dataset can be resized.  Axes with value\n",
      " |      None have no resize limit.\n",
      " |  \n",
      " |  ndim\n",
      " |      Numpy-style attribute giving the number of dimensions\n",
      " |  \n",
      " |  scaleoffset\n",
      " |      Scale/offset filter settings. For integer data types, this is\n",
      " |      the number of bits stored, or 0 for auto-detected. For floating\n",
      " |      point data types, this is the number of decimal places retained.\n",
      " |      If the scale/offset filter is not in use, this is None.\n",
      " |  \n",
      " |  shape\n",
      " |      Numpy-style shape tuple giving dataset dimensions\n",
      " |  \n",
      " |  shuffle\n",
      " |      Shuffle filter present (T/F)\n",
      " |  \n",
      " |  size\n",
      " |      Numpy-style attribute giving the total dataset size\n",
      " |  \n",
      " |  value\n",
      " |      Alias for dataset[()]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  attrs\n",
      " |      Attributes attached to this object\n",
      " |  \n",
      " |  file\n",
      " |      Return a File instance associated with this object\n",
      " |  \n",
      " |  id\n",
      " |      Low-level identifier appropriate for this object\n",
      " |  \n",
      " |  name\n",
      " |      Return the full name of this object.  None if anonymous.\n",
      " |  \n",
      " |  parent\n",
      " |      Return the parent group of this object.\n",
      " |      \n",
      " |      This is always equivalent to obj.file[posixpath.dirname(obj.name)].\n",
      " |      ValueError if this object is anonymous.\n",
      " |  \n",
      " |  ref\n",
      " |      An (opaque) HDF5 reference to this object\n",
      " |  \n",
      " |  regionref\n",
      " |      Create a region reference (Datasets only).\n",
      " |      \n",
      " |      The syntax is regionref[<slices>]. For example, dset.regionref[...]\n",
      " |      creates a region reference in which the whole dataset is selected.\n",
      " |      \n",
      " |      Can also be used to determine the shape of the referenced dataset\n",
      " |      (via .shape property), or the shape of the selection (via the\n",
      " |      .selection property).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.CommonStateObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt2 = sg2.create_dataset('random', data=np.arange(0, 12).reshape(2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"random\": shape (2, 6), type \"<i8\">"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
